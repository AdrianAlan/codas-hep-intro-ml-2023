{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00dc1241",
   "metadata": {},
   "source": [
    "# CoDaS-HEP 2023: Machine Learning Introduction and Fundamentals\n",
    "\n",
    "Material: numpy, linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995b4b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e662d93f",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook introduces Numpy and the 'simplest' ML model: linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96b698a",
   "metadata": {},
   "source": [
    "## Working with `numpy`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f432fe9a",
   "metadata": {},
   "source": [
    "A python library for handling arrays (matrices). Exercises adopted from this [lecture](https://compphysics.github.io/MachineLearningMSU/doc/pub/Introduction/html/Introduction.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f025f5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by importing\n",
    "\n",
    "import numpy as np     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386744ff",
   "metadata": {},
   "source": [
    "Let's initialize an array (vector) of 10 elements. These elements are deterimined by random numbers drawn from a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c5c8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.normal(size=10)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ba0b7d",
   "metadata": {},
   "source": [
    "You can also initialize an array with specific values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67e064f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 2, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9be9c6",
   "metadata": {},
   "source": [
    "Indexing elements. Note that Python starts numbering elements from 0!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617e707f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first element of x\n",
    "\n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff43759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the last element of x\n",
    "\n",
    "print(x[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3f1be9",
   "metadata": {},
   "source": [
    "You can also apply functions like log to an entire array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669711a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.log(np.array([4, 7, 8]))\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b776fdb7",
   "metadata": {},
   "source": [
    "Note: It's typically better to use the built in numpy functions because they're optimized!\n",
    "\n",
    "Exercise: Write a NumPy program to convert the values of Centigrade degrees into Fahrenheit degrees. Centigrade values are stored into a NumPy array.\n",
    "\n",
    "Hint: C/5=(F-32)/9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9d050e",
   "metadata": {},
   "outputs": [],
   "source": [
    "F = np.array([0, 12, 45.21, 34, 99.91])\n",
    "C = (F - 32) * 5 / 9\n",
    "print(C)\n",
    "C_exp = np.array([-17.77777778, -11.11111111, 7.33888889, 1.11111111, 37.72777778])\n",
    "\n",
    "assert np.all(np.isclose(C_exp, C, rtol=1e-05, atol=1e-08, equal_nan=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f271864",
   "metadata": {},
   "source": [
    "We can also make matrices in numpy (and tensors of higher dimension)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34be9b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.log(np.array([ [4.0, 7.0, 8.0], [3.0, 10.0, 11.0], [4.0, 5.0, 7.0] ]))\n",
    "\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f33786",
   "metadata": {},
   "source": [
    "You can get information about the matrix and easily slice it (i.e. select specific values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0afc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the matrix size\n",
    "print(\"A size:\", A.shape)\n",
    "\n",
    "# Make a new matrix B=log(A)\n",
    "B = np.log(np.array([ [4.0, 7.0, 8.0], [3.0, 10.0, 11.0], [4.0, 5.0, 7.0] ]))\n",
    "\n",
    "# Print the first column, row-major order and elements start with 0\n",
    "print(\"First column of B:\", B[:,0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99daa943",
   "metadata": {},
   "source": [
    "There are also functions to create matrices with certain values (0 or 1) or random values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de1a344",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "\n",
    "# Define a matrix of dimension 10 x 10 and set all elements to zero\n",
    "A = np.zeros( (n, n) )\n",
    "print(\"A:\", A)\n",
    "\n",
    "# Define a matrix of dimension 10 x 10 and set all elements to one\n",
    "B = np.ones( (n, n) )\n",
    "print(\"B:\", B)\n",
    "\n",
    "# Define a matrix of dimension 10 x 10 and set all elements to random numbers with x \\in [0, 1]\n",
    "C = np.random.rand(n, n)\n",
    "print(\"C:\", C) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e33349",
   "metadata": {},
   "source": [
    "## Jet Tagging: Introduction\n",
    "\n",
    "The majority of particles produced in LHC events are unstable and immediately decay to lighter particles. The new particles can decay themselves to others in a so-called decay chain. Such a process terminates when the decay products are stable particles, e.g., charged pions. This collimated shower of particles with adjacent trajectories is called a *jet*. Jets are central to many physics studies at the LHC experiments. In particular, a successful physics program requires aggregating particles into jets (jet clustering), an accurate determination of the jet momentum (momentum measurement) and the identification of which particle kind started the shower (**jet tagging**).\n",
    "\n",
    "In this excercise you will learn how to train a regressor. We will use some of jet features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9116c650",
   "metadata": {},
   "source": [
    "### Preparation of the training and validation samples\n",
    "\n",
    "If you have already downloaded the datasets you can skip the cell below. In order to import the dataset: curl the dataset repository (to import the data in Colab), load the `h5` files in, extract the data we need: a target and jet features.\n",
    "\n",
    "To type shell commands, we start the command line with !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea7f5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "! curl https://cernbox.cern.ch/s/6Ec5pGFEpFWeH6S/download -o ../Data-MLtutorial.tar.gz\n",
    "! tar -xvzf ../Data-MLtutorial.tar.gz -C ../\n",
    "! ls ../Data-MLtutorial/JetDataset/\n",
    "! rm ../Data-MLtutorial.tar.gz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b9186e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "target = np.array([])\n",
    "inputs = np.array([])\n",
    "\n",
    "datafiles = ['../Data-MLtutorial/JetDataset/jetImage_7_100p_0_10000.h5']\n",
    "\n",
    "for file_ in datafiles:\n",
    "    with h5py.File(file_, 'r') as f:\n",
    "        print(\"Appending {}\".format(file_))\n",
    "        jets = np.array(f.get('jets'))\n",
    "        tmp_inputs = np.array(f.get(\"jets\"))[:,[5, 10]] # That's `j_tau2_b1` and `j_tau32_b1`\n",
    "        tmp_target = np.array(f.get('jets'))[:,6] # That's `j_tau3_b1`\n",
    "        inputs = np.concatenate([inputs, tmp_inputs], axis=0) if inputs.size else tmp_inputs\n",
    "        target = np.concatenate([target, tmp_target], axis=0) if target.size else tmp_target\n",
    "          \n",
    "print(target.shape, inputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1beb7e4b",
   "metadata": {},
   "source": [
    "In this simple exercise we will try to regress value of $\\tau_{3}$ using $\\tau_{2}$ and $\\tau_{32}$. We could first see, how well can we fit the data using an analytical solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e97e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "inputs = inputs / 100. # Prevents numerical issues\n",
    "\n",
    "reg = LinearRegression().fit(inputs, target)\n",
    "print(\"The resulting equation: {}x + {} has a R2 score of {}\".format(\n",
    "    reg.coef_,\n",
    "    reg.intercept_,\n",
    "    reg.score(inputs, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88dc981",
   "metadata": {},
   "source": [
    "Now, let's try to implement an alternative solution that uses [gradient descent](https://ml-cheatsheet.readthedocs.io/en/latest/gradient_descent.html). Note that this exercise is just for your learning on how to optimize models according to a gradient as a way of minimizing a loss function: **(Mean Square Error)**, given by:\n",
    "\n",
    "$L(y, f(x)) = \\frac{1}{2n} \\sum\\limits^{n} (y - w^TX)^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd24971e",
   "metadata": {},
   "source": [
    "**Methods to implement (in order):**\n",
    "\n",
    "- `init_weights` - accepts an input `num_features` and sets the `coef_` and `intercept_` attributes to random values drawn from a normal distribution with mean 0 and standard deviation 1. Use a numpy array for `coef_` and a float for `intercept_`\n",
    "- `score` - accepts inputs `X` and `y_true` and outputs the $R^2$ score of the model.\n",
    "- `calc_loss` - accepts inputs `X` and `y_true` as numpy arrays. Calculates and returns the Mean Square Error loss metric with the current parameters.\n",
    "- `predict` - accepts an input `X` and outputs a prediction numpy array using the current parameters.\n",
    "- `fit` - accepts inputs `X`, `y_true` and default kwargs `max_iter`, `learning_rate` and fits a model using gradient descent. Should call `calc_grad` to get gradients from current parameters and update the parameters using the gradient.\n",
    "- `calc_grad` - accepts inputs `X` and `y_true` and, using the current parameters, outputs the gradients ([coef_grad, intercept_grad]). Does not update the parameters.\n",
    "\n",
    "**Expected R2: 0.73**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e46a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "\n",
    "    def init_weights(self, num_features):\n",
    "        \"\"\"Accepts an input num_features and sets the coef_\n",
    "        and intercept_ attributes to random values drawn from a normal distribution\n",
    "        with mean 0 and standard deviation 1.\n",
    "        Use a numpy array for coef_ and a float for intercept_\"\"\"\n",
    "        # Hint: use `np.random.normal`\n",
    "        self.coef_ = np.random.normal(size=num_features)\n",
    "        self.intercept_ = np.random.normal()\n",
    "        \n",
    "    def score(self, X, y_true):\n",
    "        \"\"\"Accepts inputs X and y_true and outputs the r2 score of the model.\"\"\"\n",
    "        y_pred = self.predict(X)\n",
    "        u = ((y_true - y_pred)**2).sum()\n",
    "        v = ((y_true - y_true.mean())**2).sum()\n",
    "        return 1 - u/v\n",
    "\n",
    "    def calc_loss(self, X, y_true):\n",
    "        \"\"\"Calculates the loss value using current coef/intercept values\"\"\"\n",
    "        y_pred = self.predict(X)\n",
    "        return np.mean((y_pred - y_true)**2)/2.\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Creates a prediction with the current coef/intercept values\"\"\"\n",
    "        return (X@self.coef_ + self.intercept_)\n",
    "\n",
    "    def fit(self, X, y_true, max_iter=10000, learning_rate=0.01):\n",
    "        \"\"\"Optimizing models according to a gradient as a way of minimizing loss.\n",
    "        Should update the coef_ and intercept_ attributes\"\"\"\n",
    "        # Hint: https://ml-cheatsheet.readthedocs.io/en/latest/gradient_descent.html#step-by-step\n",
    "        for _ in range(max_iter):\n",
    "            coef_grad, intercept_grad = self.calc_grad(X, y_true)\n",
    "            self.coef_ -= learning_rate * coef_grad\n",
    "            self.intercept_ -= learning_rate * intercept_grad\n",
    "    \n",
    "    def calc_grad(self, X, y_true):\n",
    "        \"\"\"Calculates gradients for coef/intercept values\"\"\"\n",
    "        res = y_true - self.predict(X)\n",
    "        res_mat = np.tile(res.reshape(-1, 1), (1, X.shape[1]))\n",
    "        coef_grad = -1 * np.mean(res_mat * X, axis=0)\n",
    "        intercept_grad = -1 * np.mean(res)\n",
    "        return coef_grad, intercept_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cdab30",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_regressor = LinearRegressionModel()\n",
    "my_regressor.init_weights(2)\n",
    "my_regressor.fit(inputs, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bff221",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The resulting equation: {}x + {} has a R2 score of {}\".format(\n",
    "    my_regressor.coef_,\n",
    "    my_regressor.intercept_,\n",
    "    my_regressor.score(inputs, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feed0af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(target, my_regressor.predict(inputs))\n",
    "plt.plot([0, 100], [0, 100], 'r')\n",
    "plt.xlabel('Expected')\n",
    "plt.ylabel('Predicted');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1432a0ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
